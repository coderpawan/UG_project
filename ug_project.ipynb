{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderpawan/UG_project/blob/main/ug_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sAd_rWzTmE5e"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO9tvZkMsbFF",
        "outputId": "c9d499ae-e171-4014-ebd2-ed59a4e4492d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8YBniRvsmDHd"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 1000\n",
        "channels = 3\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "learning_rate = 0.0001\n",
        "val_dir = '/content/drive/MyDrive/LULC/valid'\n",
        "train_dir = '/content/drive/MyDrive/LULC/train'\n",
        "test_dir = '/content/drive/MyDrive/LULC/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bdJywE_GpGhU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    width_shift_range = 0.15,\n",
        "    height_shift_range = 0.15,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4mTCu2xwpTRK"
      },
      "outputs": [],
      "source": [
        "validation_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqquGov0pZQN",
        "outputId": "ea9b4017-cd91-4f49-80b0-65b3b36a26b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21630 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv52qZsyueWd",
        "outputId": "05328758-c6d8-4062-930f-07306896473f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2700 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "val_data = validation_data_generator.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=val_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czNaIL7Utp06",
        "outputId": "4d674dd2-c219-4547-f407-65ec4476c192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 256, 256, 8)       224       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 8)      32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 16)      1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64, 64, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 16)        4624      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64, 64, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               1638500   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,869,834\n",
            "Trainable params: 1,868,922\n",
            "Non-trainable params: 912\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(img_height, img_width, channels)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = Adam(learning_rate=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "15ds0dL3uBJw"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mcp_save = ModelCheckpoint('PKNet.h5', save_best_only=True, monitor='val_accuracy', mode='max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvZ1YxynuFVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28be8255-e2fb-407b-89c9-a0c82b9e563d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-7699f30bd6fe>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "15/15 [==============================] - 312s 21s/step - loss: 1.5245 - accuracy: 0.4646 - val_loss: 2.4928 - val_accuracy: 0.1063\n",
            "Epoch 2/200\n",
            "15/15 [==============================] - 362s 25s/step - loss: 1.3340 - accuracy: 0.5312 - val_loss: 2.5640 - val_accuracy: 0.1094\n",
            "Epoch 3/200\n",
            "15/15 [==============================] - 280s 19s/step - loss: 1.4082 - accuracy: 0.5375 - val_loss: 2.9547 - val_accuracy: 0.1000\n",
            "Epoch 4/200\n",
            "15/15 [==============================] - 320s 22s/step - loss: 1.3270 - accuracy: 0.5188 - val_loss: 2.9319 - val_accuracy: 0.1250\n",
            "Epoch 5/200\n",
            "15/15 [==============================] - 309s 21s/step - loss: 1.1702 - accuracy: 0.5833 - val_loss: 4.5090 - val_accuracy: 0.1000\n",
            "Epoch 6/200\n",
            "15/15 [==============================] - 255s 17s/step - loss: 1.0868 - accuracy: 0.6083 - val_loss: 4.9274 - val_accuracy: 0.1156\n",
            "Epoch 7/200\n",
            "15/15 [==============================] - 244s 16s/step - loss: 1.0728 - accuracy: 0.6167 - val_loss: 4.8993 - val_accuracy: 0.0875\n",
            "Epoch 8/200\n",
            "15/15 [==============================] - 272s 19s/step - loss: 1.1011 - accuracy: 0.6167 - val_loss: 6.0926 - val_accuracy: 0.1187\n",
            "Epoch 9/200\n",
            "15/15 [==============================] - 202s 14s/step - loss: 1.1313 - accuracy: 0.6271 - val_loss: 7.8359 - val_accuracy: 0.0938\n",
            "Epoch 10/200\n",
            "15/15 [==============================] - 191s 12s/step - loss: 1.0618 - accuracy: 0.6167 - val_loss: 5.6812 - val_accuracy: 0.1156\n",
            "Epoch 11/200\n",
            "15/15 [==============================] - 244s 16s/step - loss: 0.9929 - accuracy: 0.6313 - val_loss: 7.6612 - val_accuracy: 0.1125\n",
            "Epoch 12/200\n",
            "15/15 [==============================] - 173s 11s/step - loss: 1.0973 - accuracy: 0.6229 - val_loss: 7.9042 - val_accuracy: 0.1094\n",
            "Epoch 13/200\n",
            "15/15 [==============================] - 246s 17s/step - loss: 1.0142 - accuracy: 0.6417 - val_loss: 7.5166 - val_accuracy: 0.1156\n",
            "Epoch 14/200\n",
            "15/15 [==============================] - 170s 11s/step - loss: 1.0964 - accuracy: 0.6625 - val_loss: 7.8024 - val_accuracy: 0.1000\n",
            "Epoch 15/200\n",
            "15/15 [==============================] - 181s 12s/step - loss: 1.1211 - accuracy: 0.6104 - val_loss: 6.1823 - val_accuracy: 0.1281\n",
            "Epoch 16/200\n",
            "15/15 [==============================] - 203s 13s/step - loss: 1.0346 - accuracy: 0.6653 - val_loss: 8.0281 - val_accuracy: 0.0875\n",
            "Epoch 17/200\n",
            "15/15 [==============================] - 188s 13s/step - loss: 1.0476 - accuracy: 0.6500 - val_loss: 5.2840 - val_accuracy: 0.1156\n",
            "Epoch 18/200\n",
            "15/15 [==============================] - 177s 11s/step - loss: 0.9541 - accuracy: 0.6708 - val_loss: 5.6943 - val_accuracy: 0.1000\n",
            "Epoch 19/200\n",
            "15/15 [==============================] - 172s 12s/step - loss: 1.0084 - accuracy: 0.6479 - val_loss: 5.0027 - val_accuracy: 0.1344\n",
            "Epoch 20/200\n",
            "15/15 [==============================] - 160s 10s/step - loss: 0.9886 - accuracy: 0.6646 - val_loss: 7.1052 - val_accuracy: 0.1094\n",
            "Epoch 21/200\n",
            "15/15 [==============================] - 181s 12s/step - loss: 0.9657 - accuracy: 0.6917 - val_loss: 5.0101 - val_accuracy: 0.1344\n",
            "Epoch 22/200\n",
            "15/15 [==============================] - 165s 10s/step - loss: 0.9700 - accuracy: 0.6604 - val_loss: 6.6977 - val_accuracy: 0.1000\n",
            "Epoch 23/200\n",
            "15/15 [==============================] - 117s 8s/step - loss: 1.0069 - accuracy: 0.6583 - val_loss: 4.6450 - val_accuracy: 0.1437\n",
            "Epoch 24/200\n",
            "15/15 [==============================] - 161s 11s/step - loss: 0.8881 - accuracy: 0.7000 - val_loss: 4.5604 - val_accuracy: 0.1813\n",
            "Epoch 25/200\n",
            "15/15 [==============================] - 183s 12s/step - loss: 1.0475 - accuracy: 0.6521 - val_loss: 3.7327 - val_accuracy: 0.2156\n",
            "Epoch 26/200\n",
            "15/15 [==============================] - 117s 7s/step - loss: 0.8524 - accuracy: 0.7167 - val_loss: 3.5927 - val_accuracy: 0.2344\n",
            "Epoch 27/200\n",
            "15/15 [==============================] - 124s 8s/step - loss: 0.9543 - accuracy: 0.6542 - val_loss: 2.6942 - val_accuracy: 0.2812\n",
            "Epoch 28/200\n",
            "15/15 [==============================] - 150s 10s/step - loss: 0.8863 - accuracy: 0.6938 - val_loss: 2.8140 - val_accuracy: 0.3344\n",
            "Epoch 29/200\n",
            "15/15 [==============================] - 108s 7s/step - loss: 0.8677 - accuracy: 0.7208 - val_loss: 2.4877 - val_accuracy: 0.3469\n",
            "Epoch 30/200\n",
            "15/15 [==============================] - 143s 10s/step - loss: 0.8815 - accuracy: 0.7083 - val_loss: 3.2423 - val_accuracy: 0.3219\n",
            "Epoch 31/200\n",
            "15/15 [==============================] - 119s 7s/step - loss: 0.9469 - accuracy: 0.6771 - val_loss: 1.8452 - val_accuracy: 0.4531\n",
            "Epoch 32/200\n",
            "15/15 [==============================] - 105s 7s/step - loss: 0.8127 - accuracy: 0.7042 - val_loss: 1.9250 - val_accuracy: 0.4313\n",
            "Epoch 33/200\n",
            "15/15 [==============================] - 129s 8s/step - loss: 0.9031 - accuracy: 0.6979 - val_loss: 1.8115 - val_accuracy: 0.4781\n",
            "Epoch 34/200\n",
            "15/15 [==============================] - 106s 7s/step - loss: 0.9112 - accuracy: 0.6875 - val_loss: 1.6217 - val_accuracy: 0.5063\n",
            "Epoch 35/200\n",
            "15/15 [==============================] - 103s 7s/step - loss: 0.8683 - accuracy: 0.7167 - val_loss: 1.9005 - val_accuracy: 0.5125\n",
            "Epoch 36/200\n",
            "15/15 [==============================] - 98s 6s/step - loss: 0.8929 - accuracy: 0.7042 - val_loss: 1.3424 - val_accuracy: 0.5469\n",
            "Epoch 37/200\n",
            "15/15 [==============================] - 107s 7s/step - loss: 0.9329 - accuracy: 0.6750 - val_loss: 1.3687 - val_accuracy: 0.5719\n",
            "Epoch 38/200\n",
            "15/15 [==============================] - 130s 9s/step - loss: 0.8618 - accuracy: 0.7063 - val_loss: 0.8626 - val_accuracy: 0.7156\n",
            "Epoch 39/200\n",
            "15/15 [==============================] - 121s 8s/step - loss: 0.7882 - accuracy: 0.7167 - val_loss: 1.0566 - val_accuracy: 0.6219\n",
            "Epoch 40/200\n",
            "15/15 [==============================] - 89s 6s/step - loss: 0.8126 - accuracy: 0.7021 - val_loss: 1.0962 - val_accuracy: 0.5938\n",
            "Epoch 41/200\n",
            "15/15 [==============================] - 89s 6s/step - loss: 0.8865 - accuracy: 0.6896 - val_loss: 0.9954 - val_accuracy: 0.6594\n",
            "Epoch 42/200\n",
            "15/15 [==============================] - 98s 6s/step - loss: 0.8155 - accuracy: 0.7292 - val_loss: 1.3100 - val_accuracy: 0.6719\n",
            "Epoch 43/200\n",
            "15/15 [==============================] - 127s 8s/step - loss: 0.8541 - accuracy: 0.7000 - val_loss: 1.5869 - val_accuracy: 0.5844\n",
            "Epoch 44/200\n",
            "15/15 [==============================] - 89s 6s/step - loss: 0.8348 - accuracy: 0.7312 - val_loss: 1.1075 - val_accuracy: 0.5906\n",
            "Epoch 45/200\n",
            "15/15 [==============================] - 110s 7s/step - loss: 0.8245 - accuracy: 0.6938 - val_loss: 0.9115 - val_accuracy: 0.6906\n",
            "Epoch 46/200\n",
            "15/15 [==============================] - 91s 6s/step - loss: 0.8007 - accuracy: 0.7021 - val_loss: 0.9137 - val_accuracy: 0.7250\n",
            "Epoch 47/200\n",
            "15/15 [==============================] - 90s 6s/step - loss: 0.7844 - accuracy: 0.7417 - val_loss: 1.0830 - val_accuracy: 0.6438\n",
            "Epoch 48/200\n",
            "15/15 [==============================] - 113s 8s/step - loss: 0.7480 - accuracy: 0.7417 - val_loss: 0.8637 - val_accuracy: 0.6906\n",
            "Epoch 49/200\n",
            "15/15 [==============================] - 102s 7s/step - loss: 0.8992 - accuracy: 0.7000 - val_loss: 0.9060 - val_accuracy: 0.6719\n",
            "Epoch 50/200\n",
            "15/15 [==============================] - 121s 8s/step - loss: 0.8019 - accuracy: 0.7292 - val_loss: 0.8203 - val_accuracy: 0.7250\n",
            "Epoch 51/200\n",
            "15/15 [==============================] - 110s 7s/step - loss: 0.7408 - accuracy: 0.7333 - val_loss: 0.7064 - val_accuracy: 0.7437\n",
            "Epoch 52/200\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.7435 - accuracy: 0.7354 - val_loss: 0.8447 - val_accuracy: 0.6938\n",
            "Epoch 53/200\n",
            "15/15 [==============================] - 100s 7s/step - loss: 0.8149 - accuracy: 0.7542 - val_loss: 0.7540 - val_accuracy: 0.7406\n",
            "Epoch 54/200\n",
            "15/15 [==============================] - 112s 7s/step - loss: 0.7237 - accuracy: 0.7604 - val_loss: 0.8667 - val_accuracy: 0.6719\n",
            "Epoch 55/200\n",
            "15/15 [==============================] - 82s 5s/step - loss: 0.7617 - accuracy: 0.7250 - val_loss: 0.6079 - val_accuracy: 0.7781\n",
            "Epoch 56/200\n",
            "15/15 [==============================] - 113s 8s/step - loss: 0.7482 - accuracy: 0.7333 - val_loss: 0.6643 - val_accuracy: 0.7688\n",
            "Epoch 57/200\n",
            "15/15 [==============================] - 71s 4s/step - loss: 0.8182 - accuracy: 0.7021 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "15/15 [==============================] - 80s 5s/step - loss: 0.7576 - accuracy: 0.7271 - val_loss: 0.6731 - val_accuracy: 0.7688\n",
            "Epoch 59/200\n",
            "15/15 [==============================] - 81s 5s/step - loss: 0.7907 - accuracy: 0.7312 - val_loss: 0.6676 - val_accuracy: 0.7719\n",
            "Epoch 60/200\n",
            "15/15 [==============================] - 84s 6s/step - loss: 0.7217 - accuracy: 0.7521 - val_loss: 0.5664 - val_accuracy: 0.8062\n",
            "Epoch 61/200\n",
            "15/15 [==============================] - 93s 6s/step - loss: 0.7850 - accuracy: 0.7292 - val_loss: 0.9000 - val_accuracy: 0.7125\n",
            "Epoch 62/200\n",
            "15/15 [==============================] - 75s 5s/step - loss: 0.7848 - accuracy: 0.7333 - val_loss: 0.5952 - val_accuracy: 0.7906\n",
            "Epoch 63/200\n",
            "15/15 [==============================] - 64s 4s/step - loss: 0.7300 - accuracy: 0.7667 - val_loss: 0.7083 - val_accuracy: 0.7531\n",
            "Epoch 64/200\n",
            "15/15 [==============================] - 88s 6s/step - loss: 0.8150 - accuracy: 0.7271 - val_loss: 0.6416 - val_accuracy: 0.7531\n",
            "Epoch 65/200\n",
            "15/15 [==============================] - 80s 5s/step - loss: 0.7418 - accuracy: 0.7542 - val_loss: 0.7301 - val_accuracy: 0.7625\n",
            "Epoch 66/200\n",
            "15/15 [==============================] - 68s 4s/step - loss: 0.6863 - accuracy: 0.7708 - val_loss: 0.5884 - val_accuracy: 0.8062\n",
            "Epoch 67/200\n",
            "15/15 [==============================] - 66s 4s/step - loss: 0.7265 - accuracy: 0.7521 - val_loss: 0.6866 - val_accuracy: 0.7594\n",
            "Epoch 68/200\n",
            "15/15 [==============================] - 67s 4s/step - loss: 0.7270 - accuracy: 0.7292 - val_loss: 0.5694 - val_accuracy: 0.7906\n",
            "Epoch 69/200\n",
            "15/15 [==============================] - 69s 5s/step - loss: 0.7451 - accuracy: 0.7604 - val_loss: 0.5365 - val_accuracy: 0.8156\n",
            "Epoch 70/200\n",
            "15/15 [==============================] - 64s 4s/step - loss: 0.7218 - accuracy: 0.7750 - val_loss: 0.6110 - val_accuracy: 0.7594\n",
            "Epoch 71/200\n",
            "15/15 [==============================] - 68s 5s/step - loss: 0.6480 - accuracy: 0.7875 - val_loss: 0.6833 - val_accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "15/15 [==============================] - 63s 4s/step - loss: 0.7454 - accuracy: 0.7458 - val_loss: 0.6543 - val_accuracy: 0.7844\n",
            "Epoch 73/200\n",
            "15/15 [==============================] - 92s 6s/step - loss: 0.6985 - accuracy: 0.7604 - val_loss: 0.5471 - val_accuracy: 0.8125\n",
            "Epoch 74/200\n",
            "15/15 [==============================] - 62s 4s/step - loss: 0.7686 - accuracy: 0.7437 - val_loss: 0.6480 - val_accuracy: 0.7625\n",
            "Epoch 75/200\n",
            "15/15 [==============================] - 68s 5s/step - loss: 0.7156 - accuracy: 0.7500 - val_loss: 0.6393 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "15/15 [==============================] - 82s 5s/step - loss: 0.6942 - accuracy: 0.7583 - val_loss: 0.5569 - val_accuracy: 0.7969\n",
            "Epoch 77/200\n",
            "15/15 [==============================] - 80s 5s/step - loss: 0.7217 - accuracy: 0.7417 - val_loss: 0.5640 - val_accuracy: 0.8094\n",
            "Epoch 78/200\n",
            "15/15 [==============================] - 61s 4s/step - loss: 0.7964 - accuracy: 0.7271 - val_loss: 0.5320 - val_accuracy: 0.7844\n",
            "Epoch 79/200\n",
            "15/15 [==============================] - 66s 4s/step - loss: 0.7310 - accuracy: 0.7583 - val_loss: 0.5595 - val_accuracy: 0.7812\n",
            "Epoch 80/200\n",
            "15/15 [==============================] - 71s 5s/step - loss: 0.7284 - accuracy: 0.7688 - val_loss: 0.4893 - val_accuracy: 0.8094\n",
            "Epoch 81/200\n",
            "15/15 [==============================] - 71s 5s/step - loss: 0.6611 - accuracy: 0.7937 - val_loss: 0.6673 - val_accuracy: 0.7750\n",
            "Epoch 82/200\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.6806 - accuracy: 0.7604 - val_loss: 0.5634 - val_accuracy: 0.8062\n",
            "Epoch 83/200\n",
            "15/15 [==============================] - 55s 4s/step - loss: 0.7711 - accuracy: 0.7188 - val_loss: 0.6776 - val_accuracy: 0.7875\n",
            "Epoch 84/200\n",
            "15/15 [==============================] - 60s 4s/step - loss: 0.6878 - accuracy: 0.7729 - val_loss: 0.6743 - val_accuracy: 0.7781\n",
            "Epoch 85/200\n",
            "15/15 [==============================] - 66s 4s/step - loss: 0.7174 - accuracy: 0.7771 - val_loss: 0.7113 - val_accuracy: 0.7594\n",
            "Epoch 86/200\n",
            "15/15 [==============================] - 69s 5s/step - loss: 0.6686 - accuracy: 0.7688 - val_loss: 0.7578 - val_accuracy: 0.7219\n",
            "Epoch 87/200\n",
            "15/15 [==============================] - 71s 5s/step - loss: 0.7946 - accuracy: 0.7083 - val_loss: 0.7155 - val_accuracy: 0.7656\n",
            "Epoch 88/200\n",
            "15/15 [==============================] - 69s 5s/step - loss: 0.7620 - accuracy: 0.7479 - val_loss: 0.5406 - val_accuracy: 0.8156\n",
            "Epoch 89/200\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.7904 - accuracy: 0.7250 - val_loss: 0.6495 - val_accuracy: 0.7719\n",
            "Epoch 90/200\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.7851 - accuracy: 0.7333 - val_loss: 0.6855 - val_accuracy: 0.7563\n",
            "Epoch 91/200\n",
            "15/15 [==============================] - 58s 4s/step - loss: 0.7759 - accuracy: 0.7271 - val_loss: 0.5536 - val_accuracy: 0.8094\n",
            "Epoch 92/200\n",
            "15/15 [==============================] - 67s 4s/step - loss: 0.6093 - accuracy: 0.8000 - val_loss: 0.5719 - val_accuracy: 0.8031\n",
            "Epoch 93/200\n",
            "15/15 [==============================] - 58s 4s/step - loss: 0.6636 - accuracy: 0.7688 - val_loss: 0.5673 - val_accuracy: 0.7875\n",
            "Epoch 94/200\n",
            "15/15 [==============================] - 68s 5s/step - loss: 0.7054 - accuracy: 0.7542 - val_loss: 0.4764 - val_accuracy: 0.8375\n",
            "Epoch 95/200\n",
            "15/15 [==============================] - 73s 5s/step - loss: 0.6118 - accuracy: 0.7833 - val_loss: 0.5231 - val_accuracy: 0.8188\n",
            "Epoch 96/200\n",
            "15/15 [==============================] - 72s 5s/step - loss: 0.7327 - accuracy: 0.7396 - val_loss: 0.6329 - val_accuracy: 0.8094\n",
            "Epoch 97/200\n",
            "15/15 [==============================] - 76s 5s/step - loss: 0.6999 - accuracy: 0.7521 - val_loss: 0.5441 - val_accuracy: 0.7969\n",
            "Epoch 98/200\n",
            "15/15 [==============================] - 70s 5s/step - loss: 0.6475 - accuracy: 0.7708 - val_loss: 0.5646 - val_accuracy: 0.8031\n",
            "Epoch 99/200\n",
            "15/15 [==============================] - 68s 4s/step - loss: 0.6412 - accuracy: 0.7708 - val_loss: 0.4421 - val_accuracy: 0.8375\n",
            "Epoch 100/200\n",
            "15/15 [==============================] - 68s 5s/step - loss: 0.6994 - accuracy: 0.7583 - val_loss: 0.5446 - val_accuracy: 0.8188\n",
            "Epoch 101/200\n",
            "15/15 [==============================] - 59s 4s/step - loss: 0.6206 - accuracy: 0.7958 - val_loss: 0.5243 - val_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "15/15 [==============================] - 64s 4s/step - loss: 0.6597 - accuracy: 0.7875 - val_loss: 0.7500 - val_accuracy: 0.7531\n",
            "Epoch 103/200\n",
            "15/15 [==============================] - 56s 4s/step - loss: 0.6523 - accuracy: 0.7583 - val_loss: 0.6994 - val_accuracy: 0.7656\n",
            "Epoch 104/200\n",
            "15/15 [==============================] - 62s 4s/step - loss: 0.6192 - accuracy: 0.7812 - val_loss: 0.6606 - val_accuracy: 0.7875\n",
            "Epoch 105/200\n",
            "15/15 [==============================] - 60s 4s/step - loss: 0.6831 - accuracy: 0.7708 - val_loss: 0.7417 - val_accuracy: 0.7406\n",
            "Epoch 106/200\n",
            "15/15 [==============================] - 69s 5s/step - loss: 0.6827 - accuracy: 0.7875 - val_loss: 0.6771 - val_accuracy: 0.7781\n",
            "Epoch 107/200\n",
            "15/15 [==============================] - 62s 4s/step - loss: 0.7186 - accuracy: 0.7667 - val_loss: 0.6010 - val_accuracy: 0.7969\n",
            "Epoch 108/200\n",
            "15/15 [==============================] - 63s 4s/step - loss: 0.6624 - accuracy: 0.7750 - val_loss: 0.5332 - val_accuracy: 0.8188\n",
            "Epoch 109/200\n",
            "15/15 [==============================] - 55s 4s/step - loss: 0.6075 - accuracy: 0.8042 - val_loss: 0.5616 - val_accuracy: 0.7937\n",
            "Epoch 110/200\n",
            "15/15 [==============================] - 56s 4s/step - loss: 0.6313 - accuracy: 0.8021 - val_loss: 0.8896 - val_accuracy: 0.7031\n",
            "Epoch 111/200\n",
            "15/15 [==============================] - 61s 4s/step - loss: 0.7764 - accuracy: 0.7292 - val_loss: 0.5922 - val_accuracy: 0.8000\n",
            "Epoch 112/200\n",
            "15/15 [==============================] - 60s 4s/step - loss: 0.6602 - accuracy: 0.7625 - val_loss: 0.5439 - val_accuracy: 0.8094\n",
            "Epoch 113/200\n",
            "15/15 [==============================] - 55s 4s/step - loss: 0.6088 - accuracy: 0.7792 - val_loss: 0.5680 - val_accuracy: 0.8094\n",
            "Epoch 114/200\n",
            "15/15 [==============================] - 54s 4s/step - loss: 0.7388 - accuracy: 0.7583 - val_loss: 0.4327 - val_accuracy: 0.8344\n",
            "Epoch 115/200\n",
            "15/15 [==============================] - 52s 3s/step - loss: 0.6132 - accuracy: 0.7958 - val_loss: 0.5501 - val_accuracy: 0.7844\n",
            "Epoch 116/200\n",
            "15/15 [==============================] - 58s 4s/step - loss: 0.6461 - accuracy: 0.7792 - val_loss: 0.6510 - val_accuracy: 0.7812\n",
            "Epoch 117/200\n",
            "15/15 [==============================] - 58s 3s/step - loss: 0.5663 - accuracy: 0.8042 - val_loss: 0.6614 - val_accuracy: 0.7531\n",
            "Epoch 118/200\n",
            "15/15 [==============================] - 61s 4s/step - loss: 0.5830 - accuracy: 0.8062 - val_loss: 0.6078 - val_accuracy: 0.7969\n",
            "Epoch 119/200\n",
            "15/15 [==============================] - 59s 4s/step - loss: 0.6168 - accuracy: 0.8042 - val_loss: 0.5433 - val_accuracy: 0.8219\n",
            "Epoch 120/200\n",
            "15/15 [==============================] - 53s 3s/step - loss: 0.7288 - accuracy: 0.7500 - val_loss: 0.5870 - val_accuracy: 0.7719\n",
            "Epoch 121/200\n",
            "15/15 [==============================] - 55s 4s/step - loss: 0.6137 - accuracy: 0.7937 - val_loss: 0.6177 - val_accuracy: 0.8125\n",
            "Epoch 122/200\n",
            " 9/15 [=================>............] - ETA: 17s - loss: 0.5260 - accuracy: 0.8056"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(\n",
        "    train_data,\n",
        "    epochs=200,\n",
        "    validation_data=val_data,\n",
        "    steps_per_epoch=15,\n",
        "    validation_steps=10,\n",
        "    callbacks=[mcp_save]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSueEH2qBWNX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8tp4jafBZ0_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'vaidation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34I6iGs0BtRF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'vaidation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iImGM-Y-Bzjk"
      },
      "outputs": [],
      "source": [
        "test_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjHxnopgB5IF"
      },
      "outputs": [],
      "source": [
        "test_data = test_data_generator.flow_from_directory(\n",
        "    batch_size=1,\n",
        "    directory=test_dir,\n",
        "    shuffle=False,\n",
        "    target_size=(img_height, img_width),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "idx2label_dict = {test_data.class_indices[k]: k for k in test_data.class_indices}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "codaz9XCB8cs"
      },
      "outputs": [],
      "source": [
        "import time \n",
        "\n",
        "model.load_weights('PKNet.h5')\n",
        "inference_times = []\n",
        "for i in range(5):\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict_generator(test_data, steps=2700).round()\n",
        "    inference_time = time.time() - start_time\n",
        "    inference_times.append(inference_time)\n",
        "# print('Average inference time: %.2f seconds' % (sum(inference_times)/len(inference_times)))\n",
        "y_true = test_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJrMYfZLExUK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyKvMLHKE7Rk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtbR-VxZFCPR"
      },
      "outputs": [],
      "source": [
        "def get_key(mydict,val): \n",
        "    for key, value in mydict.items(): \n",
        "         if val == value: \n",
        "             return key \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMqwLID0FGSA"
      },
      "outputs": [],
      "source": [
        "def find_metrics(y_true, y_pred, idx2label_dict, class_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    out1 = np.sum(cm, axis = 1)\n",
        "    out2 = np.sum(cm, axis = 0)\n",
        "    id = get_key(idx2label_dict, class_name)\n",
        "    r1 = cm[id][id]/out1[id]\n",
        "    r2 = cm[id][id]/out2[id]\n",
        "    s = cm[id][id]\n",
        "    return (r1, r2, s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2dAT93jG7kK"
      },
      "outputs": [],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euy3dI2tFOkP"
      },
      "outputs": [],
      "source": [
        "import prettytable\n",
        "\n",
        "table = prettytable.PrettyTable(['Class', 'Recall', 'Precision', 'Accuracy', 'F1 Score'])\n",
        "class_names = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        "sum = 0\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_sum = np.sum(cm)\n",
        "col_sum = np.sum(cm, axis = 0)\n",
        "row_sum = np.sum(cm, axis = 1)\n",
        "\n",
        "class_acc = []\n",
        "\n",
        "row = len(cm)\n",
        "\n",
        "for x in range(0,row):\n",
        "    tp = cm[x][x] \n",
        "    fp = row_sum[x] - cm[x][x]\n",
        "    fn = col_sum[x] - cm[x][x]\n",
        "    tn = cm_sum - row_sum[x]- col_sum[x] + cm[x][x]\n",
        "\n",
        "temp = (tp+tn)/(tp+fn+fp+tn)\n",
        "class_acc.append(temp)\n",
        "\n",
        "temp = 0    \n",
        "for _class in class_names:\n",
        "    result1, result2, s = find_metrics(y_true, y_pred, idx2label_dict, _class)\n",
        "    sum += s\n",
        "    f1 = (2*(result1* result2))/ (result1 + result2)\n",
        "    table.add_row([_class, round(result1, 2), round(result2, 2), round(class_acc[temp], 2), round(f1, 2)])\n",
        "    \n",
        "print(table)\n",
        "print(\"Accuracy: %.2f\" % (sum/2700*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awgZjEEYgQo-"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index = [idx2label_dict[int(i)] for i in \"0123456789\"], columns = [idx2label_dict[int(i)] for i in \"0123456789\"])\n",
        "plt.figure(figsize = (20,10))\n",
        "sn.heatmap(df_cm, annot=True, linewidths=.5, fmt=\"d\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15jzrIgbBVAZ0L-euc6ukCFqTuAy66Cwy",
      "authorship_tag": "ABX9TyNyupgyEFh5Efqg2IHNj7e+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}